{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**First, vectorize the CSV data**"
      ],
      "metadata": {
        "id": "ID6M6HRjSKKG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K2d1JPOSAs0",
        "outputId": "df2c26e8-f22f-4829-ef78-b7674ab42f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
            "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
            "features.shape: (284807, 30)\n",
            "targets.shape: (284807, 1)\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "fname = \"/content/creditcard.csv\"\n",
        "\n",
        "all_features = []\n",
        "all_targets = []\n",
        "with open(fname) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i == 0:\n",
        "            print(\"HEADER:\", line.strip())\n",
        "            continue  # Skip header\n",
        "        fields = line.strip().split(\",\")\n",
        "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
        "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
        "        if i == 1:\n",
        "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
        "\n",
        "features = np.array(all_features, dtype=\"float32\")\n",
        "targets = np.array(all_targets, dtype=\"uint8\")\n",
        "print(\"features.shape:\", features.shape)\n",
        "print(\"targets.shape:\", targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare a validation set**"
      ],
      "metadata": {
        "id": "jjV7y-K4UPHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_val_samples = int(len(features) * 0.2)\n",
        "train_features = features[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_features = features[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "print(\"Number of training samples:\", len(train_features))\n",
        "print(\"Number of validation samples:\", len(val_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFpdg1sMUS_z",
        "outputId": "5e4d6b79-2b34-4e90-cea9-1e014e275072"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 227846\n",
            "Number of validation samples: 56961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyze class imbalance in the targets**"
      ],
      "metadata": {
        "id": "n7Nni8YvUYhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = np.bincount(train_targets[:, 0])\n",
        "print(\n",
        "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
        "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
        "    )\n",
        ")\n",
        "\n",
        "weight_for_0 = 1.0 / counts[0]\n",
        "weight_for_1 = 1.0 / counts[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of8BZCCmUXhu",
        "outputId": "11790e7e-944a-4fea-89ea-ecf1bf070367"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive samples in training data: 417 (0.18% of total)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalize the data using training set statistics**"
      ],
      "metadata": {
        "id": "inS8hz2uUkZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(train_features, axis=0)\n",
        "train_features -= mean\n",
        "val_features -= mean\n",
        "std = np.std(train_features, axis=0)\n",
        "train_features /= std\n",
        "val_features /= std"
      ],
      "metadata": {
        "id": "gk9inhbmUgnE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build a binary classification model**"
      ],
      "metadata": {
        "id": "6BQDIy-aUua9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=train_features.shape[1:]),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "D-RRfAMJUth-",
        "outputId": "4cfd7efd-9cdd-4601-a0d8-300de2e5ef7a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m7,936\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,936</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,777\u001b[0m (546.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,777</span> (546.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m139,777\u001b[0m (546.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,777</span> (546.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model with class_weight argument**"
      ],
      "metadata": {
        "id": "_wabNDg4U_FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [\n",
        "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "    keras.metrics.FalsePositives(name=\"fp\"),\n",
        "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "    keras.metrics.TruePositives(name=\"tp\"),\n",
        "    keras.metrics.Precision(name=\"precision\"),\n",
        "    keras.metrics.Recall(name=\"recall\"),\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
        ")\n",
        "\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.keras\")]\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "model.fit(\n",
        "    train_features,\n",
        "    train_targets,\n",
        "    batch_size=2048,\n",
        "    epochs=30,\n",
        "    verbose=2,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(val_features, val_targets),\n",
        "    class_weight=class_weight,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2TLej2aU42-",
        "outputId": "db5d569c-f459-4f10-ee17-b78d6fac6ba5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "112/112 - 11s - 100ms/step - fn: 46.0000 - fp: 35125.0000 - loss: 2.6337e-06 - precision: 0.0105 - recall: 0.8897 - tn: 192304.0000 - tp: 371.0000 - val_fn: 9.0000 - val_fp: 1183.0000 - val_loss: 0.1244 - val_precision: 0.0528 - val_recall: 0.8800 - val_tn: 55703.0000 - val_tp: 66.0000\n",
            "Epoch 2/30\n",
            "112/112 - 8s - 71ms/step - fn: 36.0000 - fp: 6373.0000 - loss: 1.4472e-06 - precision: 0.0564 - recall: 0.9137 - tn: 221056.0000 - tp: 381.0000 - val_fn: 8.0000 - val_fp: 1858.0000 - val_loss: 0.1201 - val_precision: 0.0348 - val_recall: 0.8933 - val_tn: 55028.0000 - val_tp: 67.0000\n",
            "Epoch 3/30\n",
            "112/112 - 9s - 82ms/step - fn: 33.0000 - fp: 8625.0000 - loss: 1.4731e-06 - precision: 0.0426 - recall: 0.9209 - tn: 218804.0000 - tp: 384.0000 - val_fn: 6.0000 - val_fp: 1653.0000 - val_loss: 0.1011 - val_precision: 0.0401 - val_recall: 0.9200 - val_tn: 55233.0000 - val_tp: 69.0000\n",
            "Epoch 4/30\n",
            "112/112 - 7s - 65ms/step - fn: 25.0000 - fp: 7891.0000 - loss: 1.0994e-06 - precision: 0.0473 - recall: 0.9400 - tn: 219538.0000 - tp: 392.0000 - val_fn: 9.0000 - val_fp: 829.0000 - val_loss: 0.0673 - val_precision: 0.0737 - val_recall: 0.8800 - val_tn: 56057.0000 - val_tp: 66.0000\n",
            "Epoch 5/30\n",
            "112/112 - 11s - 98ms/step - fn: 18.0000 - fp: 6681.0000 - loss: 8.3450e-07 - precision: 0.0564 - recall: 0.9568 - tn: 220748.0000 - tp: 399.0000 - val_fn: 9.0000 - val_fp: 1156.0000 - val_loss: 0.0562 - val_precision: 0.0540 - val_recall: 0.8800 - val_tn: 55730.0000 - val_tp: 66.0000\n",
            "Epoch 6/30\n",
            "112/112 - 7s - 60ms/step - fn: 13.0000 - fp: 5818.0000 - loss: 6.4533e-07 - precision: 0.0649 - recall: 0.9688 - tn: 221611.0000 - tp: 404.0000 - val_fn: 10.0000 - val_fp: 619.0000 - val_loss: 0.0383 - val_precision: 0.0950 - val_recall: 0.8667 - val_tn: 56267.0000 - val_tp: 65.0000\n",
            "Epoch 7/30\n",
            "112/112 - 15s - 133ms/step - fn: 19.0000 - fp: 8534.0000 - loss: 8.2804e-07 - precision: 0.0446 - recall: 0.9544 - tn: 218895.0000 - tp: 398.0000 - val_fn: 5.0000 - val_fp: 2563.0000 - val_loss: 0.1177 - val_precision: 0.0266 - val_recall: 0.9333 - val_tn: 54323.0000 - val_tp: 70.0000\n",
            "Epoch 8/30\n",
            "112/112 - 15s - 134ms/step - fn: 14.0000 - fp: 7177.0000 - loss: 7.1878e-07 - precision: 0.0532 - recall: 0.9664 - tn: 220252.0000 - tp: 403.0000 - val_fn: 9.0000 - val_fp: 560.0000 - val_loss: 0.0274 - val_precision: 0.1054 - val_recall: 0.8800 - val_tn: 56326.0000 - val_tp: 66.0000\n",
            "Epoch 9/30\n",
            "112/112 - 10s - 89ms/step - fn: 13.0000 - fp: 8011.0000 - loss: 7.5756e-07 - precision: 0.0480 - recall: 0.9688 - tn: 219418.0000 - tp: 404.0000 - val_fn: 6.0000 - val_fp: 3063.0000 - val_loss: 0.1199 - val_precision: 0.0220 - val_recall: 0.9200 - val_tn: 53823.0000 - val_tp: 69.0000\n",
            "Epoch 10/30\n",
            "112/112 - 11s - 96ms/step - fn: 13.0000 - fp: 8918.0000 - loss: 8.4097e-07 - precision: 0.0433 - recall: 0.9688 - tn: 218511.0000 - tp: 404.0000 - val_fn: 12.0000 - val_fp: 247.0000 - val_loss: 0.0168 - val_precision: 0.2032 - val_recall: 0.8400 - val_tn: 56639.0000 - val_tp: 63.0000\n",
            "Epoch 11/30\n",
            "112/112 - 12s - 107ms/step - fn: 18.0000 - fp: 7582.0000 - loss: 7.9040e-07 - precision: 0.0500 - recall: 0.9568 - tn: 219847.0000 - tp: 399.0000 - val_fn: 6.0000 - val_fp: 2717.0000 - val_loss: 0.1088 - val_precision: 0.0248 - val_recall: 0.9200 - val_tn: 54169.0000 - val_tp: 69.0000\n",
            "Epoch 12/30\n",
            "112/112 - 9s - 81ms/step - fn: 23.0000 - fp: 9331.0000 - loss: 1.4174e-06 - precision: 0.0405 - recall: 0.9448 - tn: 218098.0000 - tp: 394.0000 - val_fn: 7.0000 - val_fp: 1409.0000 - val_loss: 0.0886 - val_precision: 0.0460 - val_recall: 0.9067 - val_tn: 55477.0000 - val_tp: 68.0000\n",
            "Epoch 13/30\n",
            "112/112 - 7s - 61ms/step - fn: 15.0000 - fp: 6691.0000 - loss: 1.0927e-06 - precision: 0.0567 - recall: 0.9640 - tn: 220738.0000 - tp: 402.0000 - val_fn: 13.0000 - val_fp: 94.0000 - val_loss: 0.0197 - val_precision: 0.3974 - val_recall: 0.8267 - val_tn: 56792.0000 - val_tp: 62.0000\n",
            "Epoch 14/30\n",
            "112/112 - 8s - 72ms/step - fn: 12.0000 - fp: 5048.0000 - loss: 6.9177e-07 - precision: 0.0743 - recall: 0.9712 - tn: 222381.0000 - tp: 405.0000 - val_fn: 9.0000 - val_fp: 872.0000 - val_loss: 0.0527 - val_precision: 0.0704 - val_recall: 0.8800 - val_tn: 56014.0000 - val_tp: 66.0000\n",
            "Epoch 15/30\n",
            "112/112 - 8s - 71ms/step - fn: 12.0000 - fp: 5028.0000 - loss: 6.4488e-07 - precision: 0.0745 - recall: 0.9712 - tn: 222401.0000 - tp: 405.0000 - val_fn: 7.0000 - val_fp: 1881.0000 - val_loss: 0.0800 - val_precision: 0.0349 - val_recall: 0.9067 - val_tn: 55005.0000 - val_tp: 68.0000\n",
            "Epoch 16/30\n",
            "112/112 - 12s - 107ms/step - fn: 11.0000 - fp: 6966.0000 - loss: 6.1149e-07 - precision: 0.0551 - recall: 0.9736 - tn: 220463.0000 - tp: 406.0000 - val_fn: 10.0000 - val_fp: 613.0000 - val_loss: 0.0301 - val_precision: 0.0959 - val_recall: 0.8667 - val_tn: 56273.0000 - val_tp: 65.0000\n",
            "Epoch 17/30\n",
            "112/112 - 10s - 90ms/step - fn: 8.0000 - fp: 5318.0000 - loss: 5.2337e-07 - precision: 0.0714 - recall: 0.9808 - tn: 222111.0000 - tp: 409.0000 - val_fn: 7.0000 - val_fp: 1555.0000 - val_loss: 0.0591 - val_precision: 0.0419 - val_recall: 0.9067 - val_tn: 55331.0000 - val_tp: 68.0000\n",
            "Epoch 18/30\n",
            "112/112 - 9s - 84ms/step - fn: 8.0000 - fp: 5886.0000 - loss: 4.5400e-07 - precision: 0.0650 - recall: 0.9808 - tn: 221543.0000 - tp: 409.0000 - val_fn: 11.0000 - val_fp: 330.0000 - val_loss: 0.0159 - val_precision: 0.1624 - val_recall: 0.8533 - val_tn: 56556.0000 - val_tp: 64.0000\n",
            "Epoch 19/30\n",
            "112/112 - 9s - 84ms/step - fn: 5.0000 - fp: 3694.0000 - loss: 4.6144e-07 - precision: 0.1003 - recall: 0.9880 - tn: 223735.0000 - tp: 412.0000 - val_fn: 11.0000 - val_fp: 345.0000 - val_loss: 0.0556 - val_precision: 0.1565 - val_recall: 0.8533 - val_tn: 56541.0000 - val_tp: 64.0000\n",
            "Epoch 20/30\n",
            "112/112 - 10s - 92ms/step - fn: 5.0000 - fp: 3149.0000 - loss: 3.4164e-07 - precision: 0.1157 - recall: 0.9880 - tn: 224280.0000 - tp: 412.0000 - val_fn: 10.0000 - val_fp: 519.0000 - val_loss: 0.0282 - val_precision: 0.1113 - val_recall: 0.8667 - val_tn: 56367.0000 - val_tp: 65.0000\n",
            "Epoch 21/30\n",
            "112/112 - 12s - 109ms/step - fn: 1.0000 - fp: 2996.0000 - loss: 2.2635e-07 - precision: 0.1219 - recall: 0.9976 - tn: 224433.0000 - tp: 416.0000 - val_fn: 11.0000 - val_fp: 274.0000 - val_loss: 0.0179 - val_precision: 0.1893 - val_recall: 0.8533 - val_tn: 56612.0000 - val_tp: 64.0000\n",
            "Epoch 22/30\n",
            "112/112 - 6s - 52ms/step - fn: 1.0000 - fp: 2618.0000 - loss: 2.1598e-07 - precision: 0.1371 - recall: 0.9976 - tn: 224811.0000 - tp: 416.0000 - val_fn: 12.0000 - val_fp: 135.0000 - val_loss: 0.0090 - val_precision: 0.3182 - val_recall: 0.8400 - val_tn: 56751.0000 - val_tp: 63.0000\n",
            "Epoch 23/30\n",
            "112/112 - 10s - 92ms/step - fn: 5.0000 - fp: 4040.0000 - loss: 4.1635e-07 - precision: 0.0925 - recall: 0.9880 - tn: 223389.0000 - tp: 412.0000 - val_fn: 8.0000 - val_fp: 597.0000 - val_loss: 0.0640 - val_precision: 0.1009 - val_recall: 0.8933 - val_tn: 56289.0000 - val_tp: 67.0000\n",
            "Epoch 24/30\n",
            "112/112 - 8s - 73ms/step - fn: 3.0000 - fp: 5163.0000 - loss: 4.0578e-07 - precision: 0.0742 - recall: 0.9928 - tn: 222266.0000 - tp: 414.0000 - val_fn: 9.0000 - val_fp: 1403.0000 - val_loss: 0.0528 - val_precision: 0.0449 - val_recall: 0.8800 - val_tn: 55483.0000 - val_tp: 66.0000\n",
            "Epoch 25/30\n",
            "112/112 - 8s - 70ms/step - fn: 2.0000 - fp: 3319.0000 - loss: 2.9229e-07 - precision: 0.1111 - recall: 0.9952 - tn: 224110.0000 - tp: 415.0000 - val_fn: 9.0000 - val_fp: 483.0000 - val_loss: 0.0288 - val_precision: 0.1202 - val_recall: 0.8800 - val_tn: 56403.0000 - val_tp: 66.0000\n",
            "Epoch 26/30\n",
            "112/112 - 8s - 72ms/step - fn: 1.0000 - fp: 2054.0000 - loss: 1.7834e-07 - precision: 0.1684 - recall: 0.9976 - tn: 225375.0000 - tp: 416.0000 - val_fn: 8.0000 - val_fp: 464.0000 - val_loss: 0.0273 - val_precision: 0.1262 - val_recall: 0.8933 - val_tn: 56422.0000 - val_tp: 67.0000\n",
            "Epoch 27/30\n",
            "112/112 - 6s - 54ms/step - fn: 1.0000 - fp: 1684.0000 - loss: 1.4096e-07 - precision: 0.1981 - recall: 0.9976 - tn: 225745.0000 - tp: 416.0000 - val_fn: 14.0000 - val_fp: 127.0000 - val_loss: 0.0089 - val_precision: 0.3245 - val_recall: 0.8133 - val_tn: 56759.0000 - val_tp: 61.0000\n",
            "Epoch 28/30\n",
            "112/112 - 10s - 91ms/step - fn: 0.0000e+00 - fp: 1521.0000 - loss: 1.2434e-07 - precision: 0.2152 - recall: 1.0000 - tn: 225908.0000 - tp: 417.0000 - val_fn: 13.0000 - val_fp: 137.0000 - val_loss: 0.0107 - val_precision: 0.3116 - val_recall: 0.8267 - val_tn: 56749.0000 - val_tp: 62.0000\n",
            "Epoch 29/30\n",
            "112/112 - 6s - 58ms/step - fn: 1.0000 - fp: 1751.0000 - loss: 1.5071e-07 - precision: 0.1920 - recall: 0.9976 - tn: 225678.0000 - tp: 416.0000 - val_fn: 16.0000 - val_fp: 70.0000 - val_loss: 0.0075 - val_precision: 0.4574 - val_recall: 0.7867 - val_tn: 56816.0000 - val_tp: 59.0000\n",
            "Epoch 30/30\n",
            "112/112 - 7s - 64ms/step - fn: 0.0000e+00 - fp: 1171.0000 - loss: 1.0701e-07 - precision: 0.2626 - recall: 1.0000 - tn: 226258.0000 - tp: 417.0000 - val_fn: 11.0000 - val_fp: 173.0000 - val_loss: 0.0124 - val_precision: 0.2700 - val_recall: 0.8533 - val_tn: 56713.0000 - val_tp: 64.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b0047222c20>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Conclusions\n",
        "At the end of training, out of 56,961 validation transactions, we are:\n",
        "\n",
        "* Correctly identifying 66 of them as fraudulent  \n",
        "* Missing 9 fraudulent transactions  \n",
        "* At the cost of incorrectly flagging 441 legitimate transactions  \n",
        "\n",
        "In the real world, one would put an even higher weight on class 1, so as to reflect that False Negatives are more costly than False Positives.\n",
        "\n",
        "Next time your credit card gets declined in an online purchase – this is why.\n",
        "\n",
        "Example available on HuggingFace."
      ],
      "metadata": {
        "id": "vEdhVnHDWZVO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uQi6hj3KVEue"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}